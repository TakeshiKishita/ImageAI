{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageAIを使ったモデル作成\n",
    "## データセット作成\n",
    "[スタンフォードの犬種データセット](http://vision.stanford.edu/aditya86/ImageNetDogs/)を使用する。  \n",
    "120クラス、約２万画像  \n",
    "### データのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
    "! tar -xvf images.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習用データの作成  \n",
    "ImageAIの場合、ディレクトリ名がクラス名になるので、  ディレクトリ名も合わせて整形する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs, rename\n",
    "from glob import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'Images'\n",
    "\n",
    "# ディレクトリ名を取得し、学習用、テスト用ディレクトリを作成する。\n",
    "dir_list = glob(path.join(INPUT, '*'))\n",
    "train_dir = path.join(INPUT, 'train')\n",
    "makedirs(train_dir)\n",
    "\n",
    "for dir_name in dir_list:\n",
    "    # 各ディレクトリ名前半の識別子を取り除き、学習用ディレクトリ配下の名前にリネームする。\n",
    "    new_dir = path.join(train_dir, dir_name.split('-')[1])\n",
    "    rename(dir_name, new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト用データの作成\n",
    "本当は全て学習データにしたいが、ImageAIの仕組み上テストデータを用意しないといけないので、  \n",
    "ランダムに各クラス2枚ずつテストデータにする。\n",
    "全体の約１％（なるべく学習に使いたいので、ケチっている）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = path.join(INPUT, 'test')\n",
    "makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "for  dir_name in glob(path.join(train_dir, '*')):\n",
    "    images = random.sample(glob(path.join(dir_name, '*')), 2)\n",
    "    \n",
    "    for img in images:\n",
    "        move_path = img.replace('train', 'test')\n",
    "        makedirs(path.split(move_path)[0], exist_ok=True)\n",
    "        shutil.move(img, move_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Prediction.Custom import ModelTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "num_objects = len(glob(path.join(train_dir, '*')))\n",
    "print(num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 55, 55, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 55, 55, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 55, 55, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 55, 55, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 55, 55, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 256)  0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 55, 55, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 55, 55, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 55, 55, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 55, 55, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 55, 55, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 55, 55, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 55, 55, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 55, 55, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 55, 55, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 55, 55, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           batch_normalization_10[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_23[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 14, 14, 1024) 4096        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_33[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_39[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 2048)   8192        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_46[0][0]     \n",
      "                                                                 batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_avg_pooling (GlobalAvera (None, 2048)         0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 120)          245880      global_avg_pooling[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 120)          0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,833,592\n",
      "Trainable params: 23,780,472\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Using Enhanced Data Generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20340 images belonging to 120 classes.\n",
      "Found 240 images belonging to 120 classes.\n",
      "JSON Mapping for the model classes saved to  Images/json/model_class.json\n",
      "Number of experiments (Epochs) :  500\n",
      "Epoch 1/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 4.7716 - acc: 0.0236\n",
      "Epoch 00001: saving model to Images/models/model_ex-001_acc-0.017857.h5\n",
      "635/635 [==============================] - 218s 343ms/step - loss: 4.7710 - acc: 0.0236 - val_loss: 5.2279 - val_acc: 0.0179\n",
      "Epoch 2/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 4.3987 - acc: 0.0505\n",
      "Epoch 00002: saving model to Images/models/model_ex-002_acc-0.062500.h5\n",
      "635/635 [==============================] - 198s 312ms/step - loss: 4.3985 - acc: 0.0504 - val_loss: 4.4156 - val_acc: 0.0625\n",
      "Epoch 3/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 3.9316 - acc: 0.1054\n",
      "Epoch 00004: saving model to Images/models/model_ex-004_acc-0.062500.h5\n",
      "635/635 [==============================] - 198s 312ms/step - loss: 3.9311 - acc: 0.1055 - val_loss: 4.2374 - val_acc: 0.0625\n",
      "Epoch 5/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 3.7130 - acc: 0.1349\n",
      "Epoch 00005: saving model to Images/models/model_ex-005_acc-0.125000.h5\n",
      "635/635 [==============================] - 199s 313ms/step - loss: 3.7132 - acc: 0.1349 - val_loss: 3.9196 - val_acc: 0.1250\n",
      "Epoch 6/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 3.5017 - acc: 0.1701\n",
      "Epoch 00006: saving model to Images/models/model_ex-006_acc-0.093750.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 3.5019 - acc: 0.1700 - val_loss: 4.2270 - val_acc: 0.0938\n",
      "Epoch 7/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 3.3066 - acc: 0.1994\n",
      "Epoch 00007: saving model to Images/models/model_ex-007_acc-0.151786.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 3.3071 - acc: 0.1992 - val_loss: 3.9459 - val_acc: 0.1518\n",
      "Epoch 8/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 3.1146 - acc: 0.2347\n",
      "Epoch 00008: saving model to Images/models/model_ex-008_acc-0.116071.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 3.1139 - acc: 0.2349 - val_loss: 4.1538 - val_acc: 0.1161\n",
      "Epoch 9/500\n",
      " 30/635 [>.............................] - ETA: 2:58 - loss: 2.8504 - acc: 0.2979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 1.8049 - acc: 0.5108\n",
      "Epoch 00016: saving model to Images/models/model_ex-016_acc-0.303571.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 1.8052 - acc: 0.5106 - val_loss: 3.0603 - val_acc: 0.3036\n",
      "Epoch 17/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 1.6550 - acc: 0.5464\n",
      "Epoch 00017: saving model to Images/models/model_ex-017_acc-0.276786.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 1.6543 - acc: 0.5465 - val_loss: 3.1892 - val_acc: 0.2768\n",
      "Epoch 18/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 1.5315 - acc: 0.5783\n",
      "Epoch 00018: saving model to Images/models/model_ex-018_acc-0.299107.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 1.5320 - acc: 0.5780 - val_loss: 3.1378 - val_acc: 0.2991\n",
      "Epoch 19/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 1.4040 - acc: 0.6140\n",
      "Epoch 00019: saving model to Images/models/model_ex-019_acc-0.308036.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 1.4037 - acc: 0.6141 - val_loss: 3.1000 - val_acc: 0.3080\n",
      "Epoch 20/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 1.2873 - acc: 0.6421\n",
      "Epoch 00020: saving model to Images/models/model_ex-020_acc-0.290179.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 1.2878 - acc: 0.6419 - val_loss: 3.1076 - val_acc: 0.2902\n",
      "Epoch 21/500\n",
      "375/635 [================>.............] - ETA: 1:19 - loss: 1.1445 - acc: 0.6825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.7310 - acc: 0.7972\n",
      "Epoch 00026: saving model to Images/models/model_ex-026_acc-0.339286.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.7314 - acc: 0.7970 - val_loss: 3.1007 - val_acc: 0.3393\n",
      "Epoch 27/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.6564 - acc: 0.8191\n",
      "Epoch 00027: saving model to Images/models/model_ex-027_acc-0.366071.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.6566 - acc: 0.8191 - val_loss: 3.2838 - val_acc: 0.3661\n",
      "Epoch 28/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.5885 - acc: 0.8414\n",
      "Epoch 00028: saving model to Images/models/model_ex-028_acc-0.312500.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.5887 - acc: 0.8412 - val_loss: 3.4815 - val_acc: 0.3125\n",
      "Epoch 29/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.8590\n",
      "Epoch 00029: saving model to Images/models/model_ex-029_acc-0.361607.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.5245 - acc: 0.8591 - val_loss: 3.3207 - val_acc: 0.3616\n",
      "Epoch 30/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.4663 - acc: 0.8761\n",
      "Epoch 00030: saving model to Images/models/model_ex-030_acc-0.375000.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.4665 - acc: 0.8762 - val_loss: 3.2555 - val_acc: 0.3750\n",
      "Epoch 31/500\n",
      "229/635 [=========>....................] - ETA: 2:02 - loss: 0.3995 - acc: 0.8992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.1594 - acc: 0.9637\n",
      "Epoch 00043: saving model to Images/models/model_ex-043_acc-0.392857.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.1596 - acc: 0.9636 - val_loss: 3.4232 - val_acc: 0.3929\n",
      "Epoch 44/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9603\n",
      "Epoch 00044: saving model to Images/models/model_ex-044_acc-0.366071.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.1626 - acc: 0.9603 - val_loss: 3.6579 - val_acc: 0.3661\n",
      "Epoch 45/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9670\n",
      "Epoch 00045: saving model to Images/models/model_ex-045_acc-0.397321.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.1425 - acc: 0.9670 - val_loss: 3.5512 - val_acc: 0.3973\n",
      "Epoch 46/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9706\n",
      "Epoch 00046: saving model to Images/models/model_ex-046_acc-0.357143.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.1309 - acc: 0.9706 - val_loss: 3.7042 - val_acc: 0.3571\n",
      "Epoch 47/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9703\n",
      "Epoch 00047: saving model to Images/models/model_ex-047_acc-0.397321.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.1303 - acc: 0.9703 - val_loss: 3.6966 - val_acc: 0.3973\n",
      "Epoch 48/500\n",
      " 17/635 [..............................] - ETA: 2:23 - loss: 0.1358 - acc: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9840\n",
      "Epoch 00059: saving model to Images/models/model_ex-059_acc-0.379464.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0775 - acc: 0.9840 - val_loss: 3.8032 - val_acc: 0.3795\n",
      "Epoch 60/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9854\n",
      "Epoch 00063: saving model to Images/models/model_ex-063_acc-0.410714.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0691 - acc: 0.9854 - val_loss: 3.6518 - val_acc: 0.4107\n",
      "Epoch 64/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9877\n",
      "Epoch 00064: saving model to Images/models/model_ex-064_acc-0.392857.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0588 - acc: 0.9876 - val_loss: 3.7054 - val_acc: 0.3929\n",
      "Epoch 65/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9876\n",
      "Epoch 00065: saving model to Images/models/model_ex-065_acc-0.357143.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0602 - acc: 0.9876 - val_loss: 4.0212 - val_acc: 0.3571\n",
      "Epoch 66/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9881\n",
      "Epoch 00066: saving model to Images/models/model_ex-066_acc-0.415179.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0565 - acc: 0.9880 - val_loss: 3.6035 - val_acc: 0.4152\n",
      "Epoch 67/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9877\n",
      "Epoch 00067: saving model to Images/models/model_ex-067_acc-0.415179.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 0.0590 - acc: 0.9877 - val_loss: 3.6415 - val_acc: 0.4152\n",
      "Epoch 68/500\n",
      "169/635 [======>.......................] - ETA: 2:18 - loss: 0.0668 - acc: 0.9852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9918\n",
      "Epoch 00080: saving model to Images/models/model_ex-080_acc-0.419643.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0394 - acc: 0.9918 - val_loss: 3.8469 - val_acc: 0.4196\n",
      "Epoch 81/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9921\n",
      "Epoch 00081: saving model to Images/models/model_ex-081_acc-0.383929.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0392 - acc: 0.9921 - val_loss: 3.7762 - val_acc: 0.3839\n",
      "Epoch 82/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9915\n",
      "Epoch 00082: saving model to Images/models/model_ex-082_acc-0.415179.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0403 - acc: 0.9915 - val_loss: 3.7873 - val_acc: 0.4152\n",
      "Epoch 83/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9916\n",
      "Epoch 00083: saving model to Images/models/model_ex-083_acc-0.388393.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0403 - acc: 0.9916 - val_loss: 4.0267 - val_acc: 0.3884\n",
      "Epoch 84/500\n",
      "618/635 [============================>.] - ETA: 5s - loss: 0.0409 - acc: 0.9914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9931\n",
      "Epoch 00096: saving model to Images/models/model_ex-096_acc-0.383929.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0323 - acc: 0.9931 - val_loss: 3.8137 - val_acc: 0.3839\n",
      "Epoch 97/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9950\n",
      "Epoch 00100: saving model to Images/models/model_ex-100_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0240 - acc: 0.9950 - val_loss: 3.7479 - val_acc: 0.4330\n",
      "Epoch 101/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9937\n",
      "Epoch 00101: saving model to Images/models/model_ex-101_acc-0.428571.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0287 - acc: 0.9937 - val_loss: 3.7786 - val_acc: 0.4286\n",
      "Epoch 102/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9925\n",
      "Epoch 00102: saving model to Images/models/model_ex-102_acc-0.410714.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0337 - acc: 0.9925 - val_loss: 3.9262 - val_acc: 0.4107\n",
      "Epoch 103/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9953\n",
      "Epoch 00103: saving model to Images/models/model_ex-103_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0243 - acc: 0.9952 - val_loss: 3.6848 - val_acc: 0.4464\n",
      "Epoch 104/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9950\n",
      "Epoch 00104: saving model to Images/models/model_ex-104_acc-0.415179.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0248 - acc: 0.9950 - val_loss: 3.8751 - val_acc: 0.4152\n",
      "Epoch 105/500\n",
      " 90/635 [===>..........................] - ETA: 2:38 - loss: 0.0339 - acc: 0.9913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9956\n",
      "Epoch 00116: saving model to Images/models/model_ex-116_acc-0.397321.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0199 - acc: 0.9955 - val_loss: 3.9479 - val_acc: 0.3973\n",
      "Epoch 117/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9944\n",
      "Epoch 00117: saving model to Images/models/model_ex-117_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0235 - acc: 0.9944 - val_loss: 3.9619 - val_acc: 0.4420\n",
      "Epoch 118/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9947\n",
      "Epoch 00118: saving model to Images/models/model_ex-118_acc-0.428571.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0230 - acc: 0.9947 - val_loss: 3.7131 - val_acc: 0.4286\n",
      "Epoch 119/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9951\n",
      "Epoch 00119: saving model to Images/models/model_ex-119_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0213 - acc: 0.9951 - val_loss: 3.8216 - val_acc: 0.4330\n",
      "Epoch 120/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9941\n",
      "Epoch 00120: saving model to Images/models/model_ex-120_acc-0.437500.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0230 - acc: 0.9941 - val_loss: 3.7599 - val_acc: 0.4375\n",
      "Epoch 121/500\n",
      "245/635 [==========>...................] - ETA: 1:58 - loss: 0.0171 - acc: 0.9967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9960\n",
      "Epoch 00132: saving model to Images/models/model_ex-132_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0179 - acc: 0.9960 - val_loss: 3.9820 - val_acc: 0.4330\n",
      "Epoch 133/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9955\n",
      "Epoch 00137: saving model to Images/models/model_ex-137_acc-0.401786.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0181 - acc: 0.9955 - val_loss: 3.9476 - val_acc: 0.4018\n",
      "Epoch 138/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9961\n",
      "Epoch 00138: saving model to Images/models/model_ex-138_acc-0.468750.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0162 - acc: 0.9961 - val_loss: 3.8137 - val_acc: 0.4688\n",
      "Epoch 139/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9953\n",
      "Epoch 00139: saving model to Images/models/model_ex-139_acc-0.437500.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0184 - acc: 0.9953 - val_loss: 3.8880 - val_acc: 0.4375\n",
      "Epoch 140/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9959\n",
      "Epoch 00140: saving model to Images/models/model_ex-140_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0167 - acc: 0.9959 - val_loss: 4.0318 - val_acc: 0.4330\n",
      "Epoch 141/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9959\n",
      "Epoch 00141: saving model to Images/models/model_ex-141_acc-0.410714.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0156 - acc: 0.9959 - val_loss: 3.8545 - val_acc: 0.4107\n",
      "Epoch 142/500\n",
      " 16/635 [..............................] - ETA: 2:24 - loss: 0.0104 - acc: 0.9961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9961\n",
      "Epoch 00153: saving model to Images/models/model_ex-153_acc-0.415179.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0145 - acc: 0.9961 - val_loss: 3.9695 - val_acc: 0.4152\n",
      "Epoch 154/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9966\n",
      "Epoch 00154: saving model to Images/models/model_ex-154_acc-0.401786.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 3.9004 - val_acc: 0.4018\n",
      "Epoch 155/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9966\n",
      "Epoch 00155: saving model to Images/models/model_ex-155_acc-0.437500.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0135 - acc: 0.9966 - val_loss: 3.8236 - val_acc: 0.4375\n",
      "Epoch 156/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9958\n",
      "Epoch 00156: saving model to Images/models/model_ex-156_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0147 - acc: 0.9958 - val_loss: 4.0900 - val_acc: 0.4330\n",
      "Epoch 157/500\n",
      "616/635 [============================>.] - ETA: 5s - loss: 0.0179 - acc: 0.9946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9963\n",
      "Epoch 00169: saving model to Images/models/model_ex-169_acc-0.450893.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0140 - acc: 0.9962 - val_loss: 4.0304 - val_acc: 0.4509\n",
      "Epoch 170/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9955\n",
      "Epoch 00174: saving model to Images/models/model_ex-174_acc-0.370536.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0141 - acc: 0.9955 - val_loss: 4.4381 - val_acc: 0.3705\n",
      "Epoch 175/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9960\n",
      "Epoch 00175: saving model to Images/models/model_ex-175_acc-0.419643.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0137 - acc: 0.9960 - val_loss: 3.8376 - val_acc: 0.4196\n",
      "Epoch 176/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9967\n",
      "Epoch 00176: saving model to Images/models/model_ex-176_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0108 - acc: 0.9967 - val_loss: 3.8112 - val_acc: 0.4509\n",
      "Epoch 177/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 00177: saving model to Images/models/model_ex-177_acc-0.419643.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0104 - acc: 0.9970 - val_loss: 3.8723 - val_acc: 0.4196\n",
      "Epoch 178/500\n",
      "587/635 [==========================>...] - ETA: 14s - loss: 0.0136 - acc: 0.9958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9964\n",
      "Epoch 00190: saving model to Images/models/model_ex-190_acc-0.433036.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 0.0108 - acc: 0.9964 - val_loss: 4.0459 - val_acc: 0.4330\n",
      "Epoch 191/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9963\n",
      "Epoch 00191: saving model to Images/models/model_ex-191_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0122 - acc: 0.9963 - val_loss: 3.9715 - val_acc: 0.4330\n",
      "Epoch 192/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9968\n",
      "Epoch 00192: saving model to Images/models/model_ex-192_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0096 - acc: 0.9968 - val_loss: 3.8502 - val_acc: 0.4464\n",
      "Epoch 193/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9964\n",
      "Epoch 00193: saving model to Images/models/model_ex-193_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0106 - acc: 0.9964 - val_loss: 3.6949 - val_acc: 0.4509\n",
      "Epoch 194/500\n",
      "627/635 [============================>.] - ETA: 2s - loss: 0.0104 - acc: 0.9967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9980\n",
      "Epoch 00206: saving model to Images/models/model_ex-206_acc-0.464286.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 3.7999 - val_acc: 0.4643\n",
      "Epoch 207/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9976\n",
      "Epoch 00207: saving model to Images/models/model_ex-207_acc-0.455357.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 0.0063 - acc: 0.9976 - val_loss: 3.8170 - val_acc: 0.4554\n",
      "Epoch 208/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9977\n",
      "Epoch 00208: saving model to Images/models/model_ex-208_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0056 - acc: 0.9977 - val_loss: 3.7901 - val_acc: 0.4464\n",
      "Epoch 209/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9974\n",
      "Epoch 00209: saving model to Images/models/model_ex-209_acc-0.459821.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0064 - acc: 0.9974 - val_loss: 3.7796 - val_acc: 0.4598\n",
      "Epoch 210/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9979\n",
      "Epoch 00210: saving model to Images/models/model_ex-210_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0051 - acc: 0.9979 - val_loss: 3.7863 - val_acc: 0.4464\n",
      "Epoch 211/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9977\n",
      "Epoch 00211: saving model to Images/models/model_ex-211_acc-0.459821.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0060 - acc: 0.9977 - val_loss: 3.7740 - val_acc: 0.4598\n",
      "Epoch 212/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9982\n",
      "Epoch 00212: saving model to Images/models/model_ex-212_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0050 - acc: 0.9982 - val_loss: 3.7759 - val_acc: 0.4464\n",
      "Epoch 213/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9976\n",
      "Epoch 00213: saving model to Images/models/model_ex-213_acc-0.464286.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0058 - acc: 0.9976 - val_loss: 3.7496 - val_acc: 0.4643\n",
      "Epoch 214/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9980\n",
      "Epoch 00214: saving model to Images/models/model_ex-214_acc-0.459821.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0049 - acc: 0.9980 - val_loss: 3.7455 - val_acc: 0.4598\n",
      "Epoch 215/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9969\n",
      "Epoch 00215: saving model to Images/models/model_ex-215_acc-0.473214.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0061 - acc: 0.9969 - val_loss: 3.7153 - val_acc: 0.4732\n",
      "Epoch 216/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9979\n",
      "Epoch 00216: saving model to Images/models/model_ex-216_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0051 - acc: 0.9979 - val_loss: 3.7571 - val_acc: 0.4509\n",
      "Epoch 217/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9969\n",
      "Epoch 00217: saving model to Images/models/model_ex-217_acc-0.437500.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0058 - acc: 0.9969 - val_loss: 3.7817 - val_acc: 0.4375\n",
      "Epoch 218/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9976\n",
      "Epoch 00218: saving model to Images/models/model_ex-218_acc-0.455357.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0054 - acc: 0.9976 - val_loss: 3.7860 - val_acc: 0.4554\n",
      "Epoch 219/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9981\n",
      "Epoch 00219: saving model to Images/models/model_ex-219_acc-0.464286.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 3.7890 - val_acc: 0.4643\n",
      "Epoch 220/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9978\n",
      "Epoch 00220: saving model to Images/models/model_ex-220_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 3.7678 - val_acc: 0.4464\n",
      "Epoch 221/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9976\n",
      "Epoch 00221: saving model to Images/models/model_ex-221_acc-0.455357.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0051 - acc: 0.9976 - val_loss: 3.7768 - val_acc: 0.4554\n",
      "Epoch 222/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9978\n",
      "Epoch 00222: saving model to Images/models/model_ex-222_acc-0.455357.h5\n",
      "635/635 [==============================] - 195s 308ms/step - loss: 0.0050 - acc: 0.9978 - val_loss: 3.7280 - val_acc: 0.4554\n",
      "Epoch 223/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9979\n",
      "Epoch 00223: saving model to Images/models/model_ex-223_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0052 - acc: 0.9979 - val_loss: 3.7702 - val_acc: 0.4420\n",
      "Epoch 224/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9981\n",
      "Epoch 00224: saving model to Images/models/model_ex-224_acc-0.455357.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 0.0045 - acc: 0.9981 - val_loss: 3.7488 - val_acc: 0.4554\n",
      "Epoch 225/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9977\n",
      "Epoch 00225: saving model to Images/models/model_ex-225_acc-0.441964.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0050 - acc: 0.9977 - val_loss: 3.7545 - val_acc: 0.4420\n",
      "Epoch 226/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9974\n",
      "Epoch 00226: saving model to Images/models/model_ex-226_acc-0.450893.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0054 - acc: 0.9974 - val_loss: 3.7612 - val_acc: 0.4509\n",
      "Epoch 227/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9977\n",
      "Epoch 00227: saving model to Images/models/model_ex-227_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0050 - acc: 0.9977 - val_loss: 3.7684 - val_acc: 0.4330\n",
      "Epoch 228/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9978\n",
      "Epoch 00228: saving model to Images/models/model_ex-228_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0047 - acc: 0.9978 - val_loss: 3.7587 - val_acc: 0.4464\n",
      "Epoch 229/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9972\n",
      "Epoch 00229: saving model to Images/models/model_ex-229_acc-0.459821.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0058 - acc: 0.9972 - val_loss: 3.7584 - val_acc: 0.4598\n",
      "Epoch 230/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9981\n",
      "Epoch 00230: saving model to Images/models/model_ex-230_acc-0.464286.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0045 - acc: 0.9981 - val_loss: 3.7631 - val_acc: 0.4643\n",
      "Epoch 231/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9977\n",
      "Epoch 00231: saving model to Images/models/model_ex-231_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0051 - acc: 0.9977 - val_loss: 3.7544 - val_acc: 0.4464\n",
      "Epoch 232/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9979\n",
      "Epoch 00232: saving model to Images/models/model_ex-232_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0047 - acc: 0.9979 - val_loss: 3.7876 - val_acc: 0.4330\n",
      "Epoch 233/500\n",
      "396/635 [=================>............] - ETA: 1:13 - loss: 0.0053 - acc: 0.9973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9979\n",
      "Epoch 00235: saving model to Images/models/model_ex-235_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0045 - acc: 0.9979 - val_loss: 3.7906 - val_acc: 0.4464\n",
      "Epoch 236/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9982\n",
      "Epoch 00236: saving model to Images/models/model_ex-236_acc-0.441964.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 0.0044 - acc: 0.9982 - val_loss: 3.7345 - val_acc: 0.4420\n",
      "Epoch 237/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9976\n",
      "Epoch 00237: saving model to Images/models/model_ex-237_acc-0.464286.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0050 - acc: 0.9975 - val_loss: 3.7224 - val_acc: 0.4643\n",
      "Epoch 238/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9979\n",
      "Epoch 00238: saving model to Images/models/model_ex-238_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0046 - acc: 0.9979 - val_loss: 3.7590 - val_acc: 0.4509\n",
      "Epoch 239/500\n",
      "580/635 [==========================>...] - ETA: 16s - loss: 0.0055 - acc: 0.9972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9974\n",
      "Epoch 00251: saving model to Images/models/model_ex-251_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0048 - acc: 0.9974 - val_loss: 3.7815 - val_acc: 0.4464\n",
      "Epoch 252/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9980\n",
      "Epoch 00252: saving model to Images/models/model_ex-252_acc-0.450893.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0042 - acc: 0.9980 - val_loss: 3.7694 - val_acc: 0.4509\n",
      "Epoch 253/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9973\n",
      "Epoch 00253: saving model to Images/models/model_ex-253_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0050 - acc: 0.9973 - val_loss: 3.7532 - val_acc: 0.4464\n",
      "Epoch 254/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9978\n",
      "Epoch 00254: saving model to Images/models/model_ex-254_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0050 - acc: 0.9978 - val_loss: 3.7613 - val_acc: 0.4464\n",
      "Epoch 255/500\n",
      "589/635 [==========================>...] - ETA: 14s - loss: 0.0047 - acc: 0.9979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9976\n",
      "Epoch 00267: saving model to Images/models/model_ex-267_acc-0.441964.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0045 - acc: 0.9976 - val_loss: 3.7682 - val_acc: 0.4420\n",
      "Epoch 268/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9973\n",
      "Epoch 00268: saving model to Images/models/model_ex-268_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0045 - acc: 0.9973 - val_loss: 3.7649 - val_acc: 0.4464\n",
      "Epoch 269/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9978\n",
      "Epoch 00272: saving model to Images/models/model_ex-272_acc-0.441964.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 0.0040 - acc: 0.9978 - val_loss: 3.7914 - val_acc: 0.4420\n",
      "Epoch 273/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9973\n",
      "Epoch 00273: saving model to Images/models/model_ex-273_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0050 - acc: 0.9973 - val_loss: 3.7932 - val_acc: 0.4420\n",
      "Epoch 274/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9979\n",
      "Epoch 00274: saving model to Images/models/model_ex-274_acc-0.433036.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0044 - acc: 0.9979 - val_loss: 3.7766 - val_acc: 0.4330\n",
      "Epoch 275/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9977\n",
      "Epoch 00275: saving model to Images/models/model_ex-275_acc-0.446429.h5\n",
      "635/635 [==============================] - 195s 308ms/step - loss: 0.0045 - acc: 0.9977 - val_loss: 3.7896 - val_acc: 0.4464\n",
      "Epoch 276/500\n",
      "497/635 [======================>.......] - ETA: 42s - loss: 0.0048 - acc: 0.9974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9978\n",
      "Epoch 00288: saving model to Images/models/model_ex-288_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0042 - acc: 0.9978 - val_loss: 3.7625 - val_acc: 0.4509\n",
      "Epoch 289/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9971\n",
      "Epoch 00289: saving model to Images/models/model_ex-289_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0049 - acc: 0.9971 - val_loss: 3.7560 - val_acc: 0.4464\n",
      "Epoch 290/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9980\n",
      "Epoch 00290: saving model to Images/models/model_ex-290_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0043 - acc: 0.9980 - val_loss: 3.7775 - val_acc: 0.4509\n",
      "Epoch 291/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9979\n",
      "Epoch 00291: saving model to Images/models/model_ex-291_acc-0.446429.h5\n",
      "635/635 [==============================] - 195s 308ms/step - loss: 0.0036 - acc: 0.9979 - val_loss: 3.7520 - val_acc: 0.4464\n",
      "Epoch 292/500\n",
      "474/635 [=====================>........] - ETA: 49s - loss: 0.0050 - acc: 0.9972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9975\n",
      "Epoch 00295: saving model to Images/models/model_ex-295_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0045 - acc: 0.9975 - val_loss: 3.7363 - val_acc: 0.4464\n",
      "Epoch 296/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9977\n",
      "Epoch 00296: saving model to Images/models/model_ex-296_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0043 - acc: 0.9977 - val_loss: 3.7270 - val_acc: 0.4464\n",
      "Epoch 297/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9976\n",
      "Epoch 00297: saving model to Images/models/model_ex-297_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0047 - acc: 0.9976 - val_loss: 3.7505 - val_acc: 0.4509\n",
      "Epoch 298/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9974\n",
      "Epoch 00298: saving model to Images/models/model_ex-298_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0047 - acc: 0.9974 - val_loss: 3.7213 - val_acc: 0.4464\n",
      "Epoch 299/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9984\n",
      "Epoch 00299: saving model to Images/models/model_ex-299_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0037 - acc: 0.9984 - val_loss: 3.7315 - val_acc: 0.4464\n",
      "Epoch 300/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9982\n",
      "Epoch 00300: saving model to Images/models/model_ex-300_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0040 - acc: 0.9982 - val_loss: 3.7290 - val_acc: 0.4509\n",
      "Epoch 301/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9973\n",
      "Epoch 00301: saving model to Images/models/model_ex-301_acc-0.450893.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0050 - acc: 0.9973 - val_loss: 3.7297 - val_acc: 0.4509\n",
      "Epoch 302/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9981\n",
      "Epoch 00302: saving model to Images/models/model_ex-302_acc-0.441964.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 0.0040 - acc: 0.9981 - val_loss: 3.7503 - val_acc: 0.4420\n",
      "Epoch 303/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9979\n",
      "Epoch 00303: saving model to Images/models/model_ex-303_acc-0.446429.h5\n",
      "635/635 [==============================] - 195s 308ms/step - loss: 0.0039 - acc: 0.9979 - val_loss: 3.7351 - val_acc: 0.4464\n",
      "Epoch 304/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9982\n",
      "Epoch 00304: saving model to Images/models/model_ex-304_acc-0.455357.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0039 - acc: 0.9982 - val_loss: 3.7251 - val_acc: 0.4554\n",
      "Epoch 305/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9976\n",
      "Epoch 00305: saving model to Images/models/model_ex-305_acc-0.441964.h5\n",
      "635/635 [==============================] - 195s 308ms/step - loss: 0.0046 - acc: 0.9976 - val_loss: 3.7442 - val_acc: 0.4420\n",
      "Epoch 306/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9980\n",
      "Epoch 00306: saving model to Images/models/model_ex-306_acc-0.441964.h5\n",
      "635/635 [==============================] - 197s 309ms/step - loss: 0.0041 - acc: 0.9980 - val_loss: 3.7319 - val_acc: 0.4420\n",
      "Epoch 307/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9981\n",
      "Epoch 00307: saving model to Images/models/model_ex-307_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0041 - acc: 0.9981 - val_loss: 3.7375 - val_acc: 0.4509\n",
      "Epoch 308/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9980\n",
      "Epoch 00308: saving model to Images/models/model_ex-308_acc-0.441964.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0038 - acc: 0.9980 - val_loss: 3.7216 - val_acc: 0.4420\n",
      "Epoch 309/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9978\n",
      "Epoch 00309: saving model to Images/models/model_ex-309_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0041 - acc: 0.9978 - val_loss: 3.7411 - val_acc: 0.4464\n",
      "Epoch 310/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9979\n",
      "Epoch 00310: saving model to Images/models/model_ex-310_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0044 - acc: 0.9979 - val_loss: 3.7341 - val_acc: 0.4420\n",
      "Epoch 311/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9978\n",
      "Epoch 00311: saving model to Images/models/model_ex-311_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0045 - acc: 0.9978 - val_loss: 3.7223 - val_acc: 0.4464\n",
      "Epoch 312/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9983\n",
      "Epoch 00312: saving model to Images/models/model_ex-312_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0040 - acc: 0.9983 - val_loss: 3.7294 - val_acc: 0.4464\n",
      "Epoch 313/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9977\n",
      "Epoch 00313: saving model to Images/models/model_ex-313_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0045 - acc: 0.9977 - val_loss: 3.7231 - val_acc: 0.4464\n",
      "Epoch 314/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9981\n",
      "Epoch 00314: saving model to Images/models/model_ex-314_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0038 - acc: 0.9981 - val_loss: 3.7347 - val_acc: 0.4464\n",
      "Epoch 315/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9980\n",
      "Epoch 00315: saving model to Images/models/model_ex-315_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0038 - acc: 0.9981 - val_loss: 3.7248 - val_acc: 0.4420\n",
      "Epoch 316/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9978\n",
      "Epoch 00316: saving model to Images/models/model_ex-316_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0044 - acc: 0.9978 - val_loss: 3.7291 - val_acc: 0.4464\n",
      "Epoch 317/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9980\n",
      "Epoch 00317: saving model to Images/models/model_ex-317_acc-0.450893.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0039 - acc: 0.9980 - val_loss: 3.7179 - val_acc: 0.4509\n",
      "Epoch 318/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9982\n",
      "Epoch 00318: saving model to Images/models/model_ex-318_acc-0.437500.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0043 - acc: 0.9982 - val_loss: 3.7350 - val_acc: 0.4375\n",
      "Epoch 319/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9983\n",
      "Epoch 00319: saving model to Images/models/model_ex-319_acc-0.450893.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0036 - acc: 0.9983 - val_loss: 3.7382 - val_acc: 0.4509\n",
      "Epoch 320/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9976\n",
      "Epoch 00320: saving model to Images/models/model_ex-320_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0044 - acc: 0.9976 - val_loss: 3.7397 - val_acc: 0.4464\n",
      "Epoch 321/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9977\n",
      "Epoch 00321: saving model to Images/models/model_ex-321_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0042 - acc: 0.9977 - val_loss: 3.7343 - val_acc: 0.4420\n",
      "Epoch 322/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9983\n",
      "Epoch 00322: saving model to Images/models/model_ex-322_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0038 - acc: 0.9982 - val_loss: 3.7392 - val_acc: 0.4464\n",
      "Epoch 323/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9982\n",
      "Epoch 00323: saving model to Images/models/model_ex-323_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0040 - acc: 0.9982 - val_loss: 3.7326 - val_acc: 0.4420\n",
      "Epoch 324/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9981\n",
      "Epoch 00324: saving model to Images/models/model_ex-324_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0041 - acc: 0.9981 - val_loss: 3.7317 - val_acc: 0.4464\n",
      "Epoch 325/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9978\n",
      "Epoch 00325: saving model to Images/models/model_ex-325_acc-0.441964.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0041 - acc: 0.9978 - val_loss: 3.7435 - val_acc: 0.4420\n",
      "Epoch 326/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9977\n",
      "Epoch 00326: saving model to Images/models/model_ex-326_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0041 - acc: 0.9977 - val_loss: 3.7294 - val_acc: 0.4420\n",
      "Epoch 327/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9976\n",
      "Epoch 00327: saving model to Images/models/model_ex-327_acc-0.450893.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0043 - acc: 0.9976 - val_loss: 3.7133 - val_acc: 0.4509\n",
      "Epoch 328/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9978\n",
      "Epoch 00328: saving model to Images/models/model_ex-328_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0039 - acc: 0.9978 - val_loss: 3.7285 - val_acc: 0.4464\n",
      "Epoch 329/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9980\n",
      "Epoch 00329: saving model to Images/models/model_ex-329_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0038 - acc: 0.9980 - val_loss: 3.7314 - val_acc: 0.4464\n",
      "Epoch 330/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9978\n",
      "Epoch 00330: saving model to Images/models/model_ex-330_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0042 - acc: 0.9977 - val_loss: 3.7301 - val_acc: 0.4464\n",
      "Epoch 331/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9981\n",
      "Epoch 00331: saving model to Images/models/model_ex-331_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0039 - acc: 0.9981 - val_loss: 3.7370 - val_acc: 0.4464\n",
      "Epoch 332/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9979\n",
      "Epoch 00332: saving model to Images/models/model_ex-332_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0042 - acc: 0.9979 - val_loss: 3.7209 - val_acc: 0.4464\n",
      "Epoch 333/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9977\n",
      "Epoch 00333: saving model to Images/models/model_ex-333_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0045 - acc: 0.9977 - val_loss: 3.7247 - val_acc: 0.4464\n",
      "Epoch 334/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9976\n",
      "Epoch 00334: saving model to Images/models/model_ex-334_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0044 - acc: 0.9976 - val_loss: 3.7380 - val_acc: 0.4464\n",
      "Epoch 335/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9982\n",
      "Epoch 00335: saving model to Images/models/model_ex-335_acc-0.441964.h5\n",
      "635/635 [==============================] - 196s 308ms/step - loss: 0.0037 - acc: 0.9982 - val_loss: 3.7320 - val_acc: 0.4420\n",
      "Epoch 336/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9976\n",
      "Epoch 00336: saving model to Images/models/model_ex-336_acc-0.455357.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0045 - acc: 0.9976 - val_loss: 3.7324 - val_acc: 0.4554\n",
      "Epoch 337/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9982\n",
      "Epoch 00337: saving model to Images/models/model_ex-337_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0039 - acc: 0.9982 - val_loss: 3.7198 - val_acc: 0.4464\n",
      "Epoch 338/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9976\n",
      "Epoch 00338: saving model to Images/models/model_ex-338_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0046 - acc: 0.9976 - val_loss: 3.7234 - val_acc: 0.4464\n",
      "Epoch 339/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9977\n",
      "Epoch 00339: saving model to Images/models/model_ex-339_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0042 - acc: 0.9977 - val_loss: 3.7299 - val_acc: 0.4464\n",
      "Epoch 340/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9982\n",
      "Epoch 00340: saving model to Images/models/model_ex-340_acc-0.446429.h5\n",
      "635/635 [==============================] - 196s 309ms/step - loss: 0.0040 - acc: 0.9982 - val_loss: 3.7302 - val_acc: 0.4464\n",
      "Epoch 341/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9976\n",
      "Epoch 00341: saving model to Images/models/model_ex-341_acc-0.446429.h5\n",
      "635/635 [==============================] - 197s 310ms/step - loss: 0.0041 - acc: 0.9976 - val_loss: 3.7215 - val_acc: 0.4464\n",
      "Epoch 342/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9983\n",
      "Epoch 00342: saving model to Images/models/model_ex-342_acc-0.446429.h5\n",
      "635/635 [==============================] - 198s 311ms/step - loss: 0.0038 - acc: 0.9983 - val_loss: 3.7301 - val_acc: 0.4464\n",
      "Epoch 343/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9975\n",
      "Epoch 00343: saving model to Images/models/model_ex-343_acc-0.450893.h5\n",
      "635/635 [==============================] - 195s 307ms/step - loss: 0.0047 - acc: 0.9975 - val_loss: 3.7255 - val_acc: 0.4509\n",
      "Epoch 344/500\n",
      "634/635 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9980\n",
      "Epoch 00344: saving model to Images/models/model_ex-344_acc-0.455357.h5\n",
      "635/635 [==============================] - 197s 311ms/step - loss: 0.0039 - acc: 0.9980 - val_loss: 3.7216 - val_acc: 0.4554\n",
      "Epoch 345/500\n",
      "332/635 [==============>...............] - ETA: 1:31 - loss: 0.0047 - acc: 0.9975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9cdd7f3c9e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetModelTypeAsResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetDataDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_experiments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhance_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_network_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/imageai/Prediction/Custom/__init__.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(self, num_objects, num_experiments, enhance_data, batch_size, initial_learning_rate, show_network_summary, training_image_size)\u001b[0m\n\u001b[1;32m    247\u001b[0m         model.fit_generator(train_generator, steps_per_epoch=int(num_train / batch_size), epochs=self.__num_epochs,\n\u001b[1;32m    248\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                             validation_steps=int(num_test / batch_size), callbacks=[checkpoint, lr_scheduler])\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 171\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2978\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trainer = ModelTraining()\n",
    "model_trainer.setModelTypeAsResNet()\n",
    "model_trainer.setDataDirectory(INPUT)\n",
    "model_trainer.trainModel(num_objects=num_objects, num_experiments=500, enhance_data=True, batch_size=32, initial_learning_rate=1e-4, show_network_summary=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
